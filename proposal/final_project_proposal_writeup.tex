\documentclass[11pt]{article}

% --- Margins (similar to ACL) ---
\usepackage[a4paper,margin=2.5cm]{geometry}

% --- Fonts ---
\usepackage{times}      % main text font
\usepackage{latexsym}   % symbols for NLP-style papers
\usepackage{url}        % for urls

% --- Japanese language support ---
\usepackage[utf8]{inputenc}
\usepackage{CJKutf8}

\usepackage{amsmath}
\usepackage{booktabs}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{verbatim}
\usepackage[square,numbers]{natbib}  % For bibliography management with square brackets


% --- Section spacing (ACL style tweaks) ---
\usepackage{titlesec}
\titlespacing*{\section}{0pt}{2ex plus 1ex minus .2ex}{1.5ex plus .2ex}
\titlespacing*{\subsection}{0pt}{1.8ex plus .5ex minus .2ex}{0.8ex plus .2ex}
\titlespacing*{\subsubsection}{0pt}{1.5ex plus .5ex minus .2ex}{0.5ex plus .2ex}

% --- Caption styling ---
\usepackage{caption}
\captionsetup{font=small, labelfont=bf}

\title{Final Project Proposal}
\author{
\begin{tabular}{c c c}
YuChen (Jean) Lin & Pakhi Chatterjee & Aditya Pandey\\
\texttt{lin.4842@osu.edu} & \texttt{chatterjee.197@osu.edu} & \texttt{pandey.172@osu.edu}
\end{tabular}
}
\date{}

\begin{document}

\maketitle

\section{Problem Statement}
Toxic comment detection models for Japanese are typically trained and evaluated on native-script text (kanji/kana). In practice, however, social text often appears in rōmaji (romanized Japanese) for ease of typing, stylistic effect, or to evade filters. Yet most open models are not evaluated for \textit{script invariance}: whether predictions stay stable when only the script changes and the underlying Japanese sentence stays the same. \\
\\
If a model flags \begin{CJK}{UTF8}{min}最低だ\end{CJK} as toxic but misses the semantically identical "saiteida," moderation quality and fairness suffer. Recent Japanese toxicity resources exist, but they focus on native script; a paired, cross-script robustness evaluation is missing. We target that gap by building a lightweight script-invariant toxicity pipeline and a paired testbed that measures label stability when only the script changes. 

\section{Motivation}
Japan has tightened penalties for online insults in 2022, making serious cases punishable by up to one year of imprisonment, so reliable toxicity detection in Japanese is no longer just an academic concern. At the same time, moderation quality is known to be uneven outside English, with evidence of under-investment and patchy language coverage across platforms. Romanized Japanese is ubiquitous because standard IMEs accept rōmaji keystrokes and convert them to kana/kanji; users can also intentionally leave text unconverted. \\
\\
If safety systems only work reliably on native script, they will systematically miss toxic content written in rōmaji and treat some speakers less fairly than others. We therefore treat romanized Japanese as a \textit{first-class input type} and ask whether modern models actually behave robustly under script changes.  

\section{Research Gap}
Recent Japanese toxicity datasets such as LLM-jp's Japanese Toxicity Dataset (v2)\cite{llmjp2024toxicity} provide manually labeled toxic comments in native Japanese to support safer LLMs. Industry work on Japanese toxicity detection emphasizes efficiency and deployment concerns but similarly evaluates almost exclusively on native script. Parallel native/romanized benchmarks for Japanese toxicity are, to our knowledge, missing. \\
\\
Romanized text has been recognized as a real failure mode in other languages. For example, Roman Urdu hate-speech detection work constructs dedicated datasets and models because romanization changes surface forms and challenges tokenizers \cite{mathur2020hateval}. A recent Nature-style line of work on multilingual toxicity \cite{nature2024multilingual} highlights script-agnostic robustness as a key requirement for safe moderation, but no equivalent study has focused on Japanese rōmaji. \\
\\
Separately, modern NLP offers heterogeneous modeling approaches:
\begin{itemize}
\item \textbf{Language-specific subword models} such as Japanese BERT \cite{bertjapanesemodel} are strong native-script baselines widely fine-tuned for Japanese tasks.
\item \textbf{Multilingual subword models} such as mDeBERTa-v3 \cite{mdebertav3model} are pre-trained on the CC100 corpus covering ~100 languages, including Japanese, offering a cross-lingual baseline.
\item \textbf{Tokenizer-free models} such as ByT5 \cite{googlebyt5model} operate directly on raw UTF-8 bytes rather than on subword tokens, and are advertised as more robust to spelling noise and script issues.
\end{itemize}
However, we lack a systematic comparison of these model families on a script-controlled Japanese toxicity benchmark. This project fills that gap by building a paired native/rōmaji Japanese toxicity dataset and comparing how a language-specific subword model, a multilingual subword model, and a tokenizer-free byte-level model behave under script changes.

\section{Technical Resources and Datasets}
\subsection{Models}
We plan to fine-tune and compare three transformer models that differ primarily in their tokenization strategy:
\begin{itemize}
\item Japanese-specific subword model (Specialist)
\begin{itemize}
\item \textbf{Base model}: {\fontfamily{helvet}\selectfont tohoku-nlp/bert-base-japanese-v3} \cite{bertjapanesemodel}
\item A BERT variant pre-trained specifically on Japanese corpora, providing a strong native-script subword baseline.
\end{itemize}
\item Multilingual subword model (Generalist)
\begin{itemize}
\item \textbf{Base model}: {\fontfamily{helvet}\selectfont microsoft/mdeberta-v3-base} \cite{mdebertav3model}
\item A multilingual DeBERTa-v3 model trained on the CC100 corpus, representing a high-capacity subword model with broad cross-lingual coverage.
\end{itemize}
\item Tokenizer-free byte-level model
\begin{itemize}
\item \textbf{Base model}: {\fontfamily{helvet}\selectfont google/byt5-small} \cite{googlebyt5model}
\item A byte-level T5 variant that operates directly on UTF-8 bytes instead of subword tokens, designed to be robust to spelling and script variation.
\end{itemize}
\end{itemize}
Each model will be equipped with a standard classification head for strict binary toxicity prediction.

\subsection{Training Datasets and Standardized Schema}
We use two public Japanese toxicity datasets:
\begin{itemize}
\item llm-jp-toxicity-dataset-v2 \cite{llmjp2024toxicity}: native Japanese sentences with multi-annotator toxicity labels.
\item inspection-ai/japanese-toxic-dataset \cite{inspection2024japanese}: native Japanese sentences with a three-way toxicity label and category flags.
\end{itemize} 
Both are passed through a Python script which converts them into a single standardized CSV format with:
%{\fontfamily{tgbonum}\selectfont }
\begin{itemize}
\item one row per text ({\fontfamily{qcr}\selectfont id}, {\fontfamily{qcr}\selectfont text\_native}),
\item a unified four-way fine label ({\fontfamily{qcr}\selectfont Not Toxic}, {\fontfamily{qcr}\selectfont Hard to Say}, {\fontfamily{qcr}\selectfont Toxic}, {\fontfamily{qcr}\selectfont Very Toxic}),
\item a three-way coarse label ({\fontfamily{qcr}\selectfont NonToxic}, {\fontfamily{qcr}\selectfont Ambiguous}, {\fontfamily{qcr}\selectfont Toxic}),
\item and lightweight metadata (category list, original labels, basic confidence).
\end{itemize}
Currently we are mainly working with a Binary Strict view, where we drop rows whose coarse label is {\fontfamily{qcr}\selectfont Ambiguous} and keep only clearly non-toxic vs clearly toxic examples.

\subsection{Paired Native/Rōmaji Views}
From each standardized CSV, we create a paired native/rōmaji view using another Python script. For every example that survives the Binary Strict filter, we:
\begin{itemize}
\item keep the original {\fontfamily{qcr}\selectfont id}, labels, and {\fontfamily{qcr}\selectfont text\_native}
\item add a romanized version of the same text as {\fontfamily{qcr}\selectfont text\_romaji}
\item and save one processed file per source.
\end{itemize}
This produces two separate processed files, one for each dataset. Each row is therefore a matched pair (native vs rōmaji) with the same label, which is exactly what we need to evaluate script robustness.

\subsection{Romanization Pipeline}
We romanize Japanese using pykakasi (v2.2+) \cite{pykakasi2024} with a simple, fixed policy:
\begin{itemize}
\item First normalize text with Unicode NFKC.
\item Use Hepburn-style romanization.
\item Do not insert word separators and do not use capitalization or macrons (long vowels are rendered in plain ASCII, e.g., “ou”, “oo”).
\end{itemize}
This gives us deterministic, ASCII-only rōmaji that roughly matches how Japanese is often typed online, and keeps the romanization behavior consistent across all experiments.

\subsection{Compute Resources}
\begin{itemize}
\item Single GPU instance (e.g., NVIDIA V100, 16 GB) 
\item Python 3.9, PyTorch, Hugging Face Transformers
\end{itemize}

\section{Proposed Approach}
\subsection{Data Preprocessing and Validation}
Our preprocessing has two separate scripted stages per dataset:
\begin{enumerate}
\item \textbf{Standardization}\\
We run our data loading Python script on the raw Inspection-AI and LLM-jp files. This aligns them into the shared schema (same label space, same column names, stable IDs) and creates the coarse toxicity label we use for Binary Strict experiments.
\item \textbf{Binary + Pairing}\\
We then run our pairing script on each standardized CSV. This script:
\begin{itemize}
\item filters out rows with an {\fontfamily{qcr}\selectfont Ambiguous} coarse label (Binary Strict view),
\item generates {\fontfamily{qcr}\selectfont text\_romaji} from {\fontfamily{qcr}\selectfont text\_native} using the romanization pipeline above,
\item and writes the paired native/rōmaji CSVs in the processed data folder.
\end{itemize}
\end{enumerate}
Some light sanity checks (spot-checking rows to make sure the rōmaji looks reasonable, and that IDs and labels are preserved) as a final data validation check.

\subsection{Model Fine-tuning}
\begin{itemize}
\item Train each model on both native Japanese and romanized (rōmaji) text independently to measure script-invariance
\item Implement stratified train/test split (80/20) to maintain toxicity class distribution and ensure reproducibility via fixed random seed
\item Use standard hyperparameters: learning rate 2e-5, batch size 16, 3 epochs, AdamW optimizer, dropout 0.1
\item Save best model checkpoint based on validation accuracy for each configuration (model × script type)
\end{itemize} 

\section{Evaluation}
\subsection{Classification Performance}
\begin{itemize}
\item F1\_native: Precision, Recall, and F1-score on the held-out native-script test set (per level and macro-averaged)
\item F1\_rōmaji: Precision, Recall, and F1-score on the held-out rōmaji test set (per level and macro-averaged)
\end{itemize}

\subsection{Script-Invariance Gap}
\begin{itemize}
\item For each toxicity level:
\[
\Delta F_1 = F_{1,\text{native}} - F_{1,\text{r\={o}maji}}
\]
report mean $\Delta$F1 and 95\% confidence interval
\item Label Consistency Rate: \% of test instances whose predicted label is identical in native and rōmaji forms (Flip rate = 1 - Consistency).
\end{itemize}

\subsection{Statistical Significance}
\begin{itemize}
\item McNemar's Test: Conduct McNemar's test on paired native versus rōmaji predictions to determine if the difference in error rates is statistically significant
\end{itemize}

\subsection{Robustness to Romanization Variants}
\begin{itemize}
\item For each common perturbation (long-vowel representation, gemination, numeric leet), compute 
\[
\Delta F_{1,\text{variant}} = F_{1,\text{r\={o}maji}} - F_{1,\text{variant}}
\]
report mean and standard deviation
\end{itemize}

\subsection{Error Analysis on Romanized Inputs}
\begin{itemize}
\item High-$\Delta$F1 Case Review: Manually examine the top 50 samples with the largest native–rōmaji F1 discrepancy to identify systematic romanization failure modes
\end{itemize}

\subsection{Efficiency Metrics for Deployment (Optional)}
\begin{itemize}
\item Inference latency (ms/sample) and throughput (samples/s) on GPU and CPU
\item Peak GPU memory usage during batch inference
\end{itemize}

\subsection{Tokenization vs Tokenization-free Model Comparison}
\label{subsec:tokenization-comparison}
The goal is to evaluate whether tokenization-free models (ByT5) maintain better toxicity detection performance across scripts compared to tokenized models (BERT Japanese, mDeBERTa).

\subsubsection{Comparative Performance Metrics}
\begin{itemize}
\item \textbf{Script-Invariance Gap:} For each model, compute $\Delta F_1 = F_{1,\text{native}} - F_{1,\text{romaji}}$. Compare:
  \begin{itemize}
  \item Tokenized models (BERT Japanese, mDeBERTa): Expected larger $|\Delta F_1|$ due to tokenization mismatch on romaji
  \item Tokenization-free (ByT5): Expected smaller $|\Delta F_1|$ due to byte-level robustness
  \end{itemize}
\item \textbf{Toxic Recall Degradation:} Measure $\Delta \text{Recall}_{\text{toxic}} = \text{Recall}_{\text{native}} - \text{Recall}_{\text{romaji}}$ to assess which architecture better preserves toxic detection capability across scripts
\item \textbf{Macro-averaged F1 Comparison:} Report macro F1 on romaji test set for all three models to directly compare overall performance on romanized text
\end{itemize}

\subsubsection{Tokenized Model Diagnostic Metrics}
Specific failure modes for BERT Japanese and mDeBERTa on romaji:
\begin{itemize}
\item \textbf{Out-of-Vocabulary (OOV) Rate:} Percentage of romaji tokens not in the model's vocabulary
\item \textbf{Unknown Token Frequency:} Count of [UNK] tokens per sentence when processing romaji text
\item \textbf{Tokenization Granularity:} Average tokens per sentence (native vs romaji) to quantify fragmentation
\item \textbf{MeCab Fragmentation Examples:} For BERT Japanese, identify cases where MeCab incorrectly segments romaji
\end{itemize}

\subsubsection{Tokenization-free Model Advantage Metrics}
Robustness characteristics of ByT5:
\begin{itemize}
\item \textbf{Perturbation Resilience:} Introduce controlled noise (typos, spacing variations, vowel length ambiguity) to romaji. Measure F1 degradation: $\Delta F_{1,\text{perturbed}} = F_{1,\text{clean}} - F_{1,\text{noisy}}$. Hypothesis: ByT5 shows minimal degradation
\item \textbf{Character-level Robustness:} Test on romanization variants (e.g., "ou" vs "ō", "kka" vs "kka"). Compare error rates across model types
\end{itemize}

\subsubsection{Cross-Architecture Analysis}
\begin{itemize}
\item \textbf{Prediction Agreement:} Calculate Cohen's Kappa between each tokenized model and ByT5 on romaji predictions. Kappa values: $\kappa < 0.6$ indicates moderate or lower agreement, suggesting tokenization-induced prediction differences; $\kappa > 0.8$ indicates substantial agreement, suggesting tokenization is not the primary factor affecting predictions
\item \textbf{Error Type Distribution and Pattern Analysis:} For romaji test set, categorize errors into four types:
  \begin{itemize}
  \item Type A: Both tokenized and tokenization-free models correct
  \item Type B: Tokenized models fail, ByT5 succeeds (tokenization failure)
  \item Type C: ByT5 fails, tokenized models succeed (byte-level limitation)
  \item Type D: Both fail (inherently difficult samples)
  \end{itemize}
  Report percentage distribution and analyze Type B vs Type C ratio. For Type B and Type C cases, conduct qualitative analysis to identify systematic patterns (e.g., linguistic features, token characteristics, sequence length) that distinguish when tokenization vs byte-level processing fails
\item \textbf{Computational Cost-Benefit Analysis:}
  \begin{itemize}
  \item Inference latency (ms): median and 95th percentile across 1000 samples
  \item GPU memory usage (MB): peak allocation during batch inference (batch size = 16)
  \item Throughput (samples/second): processing speed on full test set
  \item Robustness gain per computational unit: $\frac{\Delta F_1 \text{ improvement}}{\text{inference time ratio}}$ comparing ByT5 to fastest tokenized model. Higher value indicates better efficiency trade-off (more robustness improvement per unit of computational cost); lower value indicates worse trade-off (expensive computational cost for small gains)
  \end{itemize}
\end{itemize}

\section{Actual Outcomes}

This section summarizes what we have accomplished so far. We've completed the basic implementation and initial testing of our models. While we haven't finished everything we planned, we've made good progress and learned important things about how these models work with Japanese and romaji text.

\subsection{Preliminary Results}
We successfully implemented and evaluated three model architectures on paired native Japanese and romanized toxicity datasets (743 test samples). Key findings:

\subsubsection{Script-Invariance Performance}
\begin{table}[h]
\centering
\small
\begin{tabular}{lccccc}
\toprule
\textbf{Model} & \textbf{Script} & \textbf{Accuracy} & \textbf{Macro F1} & \textbf{Toxic Recall} & $\Delta F_1$ \\
\midrule
mDeBERTa-v3 & Native & 0.91 & 0.90 & 0.87 & \multirow{2}{*}{-0.13} \\
            & Romaji & 0.77 & 0.77 & 0.90 & \\
\midrule
BERT Japanese & Native & 0.88 & 0.88 & 0.98 & \multirow{2}{*}{-0.12} \\
              & Romaji & 0.78 & 0.76 & 0.61 & \\
\midrule
ByT5-small & Native & 0.83* & - & - & \multirow{2}{*}{TBD} \\
           & Romaji & 0.17* & - & - & \\
\bottomrule
\multicolumn{6}{l}{\footnotesize *Quick test mode (50 samples, 1 epoch) - full evaluation pending}
\end{tabular}
\caption{Model performance on native Japanese vs romaji toxicity detection}
\label{tab:results}
\end{table}

\subsubsection{Key Findings}
\begin{itemize}
\item \textbf{Tokenized Models Show Script Degradation:} Both mDeBERTa and BERT Japanese experience 12-13 point drops in macro F1 when switching from native to romaji ($\Delta F_1 \approx -0.12$), confirming our hypothesis about tokenization-induced brittleness
\item \textbf{Different Failure Modes:}
  \begin{itemize}
  \item \textit{mDeBERTa on romaji}: Low non-toxic recall (0.69) but high toxic recall (0.90) - tends to over-predict toxicity
  \item \textit{BERT Japanese on romaji}: High non-toxic recall (0.89) but low toxic recall (0.61) - misses 39\% of toxic content, likely due to MeCab tokenizer failures on romanized text
  \end{itemize}
\item \textbf{ByT5 Requires Further Investigation:} Preliminary results show poor performance on romaji (0.17 accuracy), suggesting training instability or implementation issues that need debugging
\item \textbf{Paired Dataset Established:} Successfully created 743-sample paired native/romaji test set enabling direct script-invariance evaluation
\end{itemize}

\subsection{Deliverables Completed}
\begin{itemize}
\item Paired native-romaji Japanese toxicity benchmark (inspection-ai dataset, binary classification)
\item Training pipeline supporting three model architectures with script selection (--use-romaji flag)
\item Reproducible training scripts with fixed random seeds and stratified splits
\item Comprehensive evaluation metrics: accuracy, precision, recall, F1 (per-class and macro-averaged), confusion matrices
\item Model checkpoints and result files for mDeBERTa and BERT Japanese on both scripts
\end{itemize}

\section{Future Work}

We still have several important tasks to finish before we can fully answer our research questions. This section outlines what we need to do next, organized by priority. The main challenge is getting ByT5 to work properly so we can compare it fairly with the other models.

To complete the research objectives outlined in this proposal, the following tasks remain:

\subsection{Immediate Priorities}
\begin{itemize}
\item \textbf{Debug ByT5 Training:} Investigate the poor romaji performance (0.17 accuracy). Potential issues include:
  \begin{itemize}
  \item Encoder-only usage in current implementation vs full encoder-decoder architecture
  \item Learning rate or batch size unsuitable for byte-level models
  \item Insufficient training epochs (currently 1 epoch in quick test, 3 in full mode)
  \end{itemize}
  Implement proper T5 fine-tuning with decoder inputs or switch to ByT5-base encoder representations
\item \textbf{Full-Scale ByT5 Training:} Train ByT5 on complete dataset with sufficient epochs to enable fair comparison with tokenized models
\item \textbf{Compute Comprehensive Metrics:} Calculate all proposed evaluation metrics from Section~\ref{subsec:tokenization-comparison}, including OOV rates, tokenization granularity, and Cohen's Kappa
\end{itemize}

\subsection{Advanced Analysis}
\begin{itemize}
\item \textbf{Error Type Distribution:} Implement the 4-type taxonomy (Type A/B/C/D) to quantify when tokenized vs tokenization-free models fail
\item \textbf{Tokenization Artifact Analysis:} 
  \begin{itemize}
  \item Measure [UNK] token frequency for BERT Japanese on romaji
  \item Analyze MeCab segmentation failures on romanized text
  \item Compare tokenization granularity (tokens/sentence) across native vs romaji for each model
  \end{itemize}
\end{itemize}

\subsection{Efficiency and Deployment Metrics}
\begin{itemize}
\item \textbf{Computational Cost-Benefit Analysis:} Measure inference latency, GPU memory usage, and throughput for all three models
\item \textbf{Calculate Robustness Gain per Computational Unit:} Quantify whether ByT5's potential robustness improvements justify computational overhead
\end{itemize}

\section{Expected Final Outcomes}

Once we complete all the tasks listed in the Future Work section, we expect to have clear answers to our research questions. This section describes what we hope to achieve and how our work will contribute to Japanese NLP research and practical toxicity detection systems.

\subsection{Research Contributions}
\begin{itemize}
\item \textbf{Script-Invariance Benchmark:} First comprehensive paired native/romaji evaluation for Japanese toxicity detection, demonstrating whether current models maintain fairness across script changes
\item \textbf{Tokenization vs Tokenization-free Comparison:} Quantitative evidence on whether byte-level models (ByT5) outperform subword tokenized models (BERT Japanese, mDeBERTa) on romanized text
\item \textbf{Failure Mode Taxonomy:} Systematic characterization of when and why tokenization breaks down on romaji (MeCab segmentation errors, OOV rates, [UNK] tokens) vs when byte-level processing fails
\end{itemize}

\subsection{Practical Deliverables}
\begin{itemize}
\item \textbf{Reproducible Training Pipeline:} Open-source code supporting multiple model architectures with script selection, enabling researchers to extend this work
\item \textbf{Paired Dataset:} 743-sample (expandable to larger datasets) benchmark with native Japanese and Hepburn romaji versions for controlled script-invariance testing
\item \textbf{Model Performance Baselines:} Published results for mDeBERTa-v3, BERT Japanese, and ByT5 on both native and romaji, establishing performance expectations for future work
\end{itemize}

\subsection{Key Insights}
\begin{itemize}
\item \textbf{Efficiency-Robustness Trade-offs:} Quantified computational cost (inference latency, memory) vs script-invariance gains, informing deployment decisions
\item \textbf{Architectural Recommendations:} Evidence-based guidance on when to use tokenization-free models for Japanese (and by extension, other languages with romanization)
\item \textbf{Generalization Potential:} Insights applicable to Korean, Arabic, Hindi, and other languages where romanization creates script-invariance challenges
\end{itemize}

\subsection{Impact on Japanese NLP}
\begin{itemize}
\item \textbf{Moderation Fairness:} Demonstrate whether existing models systematically disadvantage users who write in romaji, highlighting gaps in current content moderation systems
\item \textbf{Model Selection Criteria:} Provide practitioners with quantitative metrics to choose between models based on deployment context (native-only vs mixed-script environments)
\item \textbf{Future Research Directions:} Identify remaining challenges (e.g., ByT5 training stability, perturbation robustness) to guide next-generation toxicity detection research
\end{itemize} 

\begin{thebibliography}{9}

\bibitem{mathur2020hateval}
Hammad Rizwan, Muhammad Haroon Shakeel, and Asim Karim. 2020. Hate-Speech and Offensive Language Detection in Roman Urdu.
\textit{In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)}, pages 2512–2522, Online. Association for Computational Linguistics.
\url{https://doi.org/10.18653/v1/2020.emnlp-main.197}

\bibitem{nature2024multilingual}
Ashiq, W., Kanwal, S., Rafique, A. et al. Roman urdu hate speech detection using hybrid machine learning models and hyperparameter optimization. Sci Rep 14, 28590 (2024).
\url{https://doi.org/10.1038/s41598-024-79106-7}

\bibitem{bertjapanesemodel}
Tohoku NLP. (n.d.). \textit{bert-base-japanese-v3}. Hugging Face.\\
\url{https://huggingface.co/tohoku-nlp/bert-base-japanese-v3}

\bibitem{mdebertav3model}
Microsoft. (n.d.). \textit{mdeberta-v3-base}. Hugging Face.\\
\url{https://huggingface.co/microsoft/mdeberta-v3-base}

\bibitem{googlebyt5model}
Google. (n.d.). \textit {byt5-small}. Hugging Face.\\
\url{https://huggingface.co/google/byt5-small}

\bibitem{llmjp2024toxicity}
LLM-jp Consortium (2024).
\textit{Japanese Toxicity Dataset v2}.
\url{https://gitlab.llm-jp.nii.ac.jp/datasets/llm-jp-toxicity-dataset-v2}

\bibitem{inspection2024japanese}
Inspection AI (2024).
\textit{Japanese Toxic Dataset}.
\url{https://github.com/inspection-ai/japanese-toxic-dataset}

\bibitem{pykakasi2024}
pykakasi Development Team (2024).
\textit{pykakasi: Japanese text transliteration library}.
\url{https://pypi.org/project/pykakasi}

\bibitem{emnlp2022industry}
Oikawa, Yuto, Yuki Nakayama, and Koji Murakami. 2022. 
\textit{A Stacking-based Efficient Method for Toxic Language Detection on Live Streaming Chat.} 
In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing: Industry Track, pages 571–578, Abu Dhabi, United Arab Emirates. Association for Computational Linguistics.
\url{https://doi.org/10.18653/v1/2022.emnlp-industry.58}

\end{thebibliography} 

\end{document}