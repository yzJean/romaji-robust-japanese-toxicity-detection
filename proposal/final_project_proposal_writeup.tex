\documentclass[11pt]{article}

% --- Margins (similar to ACL) ---
\usepackage[a4paper,margin=2.5cm]{geometry}

% --- Fonts ---
\usepackage{times}      % main text font
\usepackage{latexsym}   % symbols for NLP-style papers
\usepackage{url}        % for urls

% --- Japanese language support ---
\usepackage[utf8]{inputenc}
\usepackage{CJKutf8}

\usepackage{amsmath}
\usepackage{booktabs}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{verbatim}
\usepackage[square,numbers]{natbib}  % For bibliography management with square brackets


% --- Section spacing (ACL style tweaks) ---
\usepackage{titlesec}
\titlespacing*{\section}{0pt}{2ex plus 1ex minus .2ex}{1.5ex plus .2ex}
\titlespacing*{\subsection}{0pt}{1.8ex plus .5ex minus .2ex}{0.8ex plus .2ex}
\titlespacing*{\subsubsection}{0pt}{1.5ex plus .5ex minus .2ex}{0.5ex plus .2ex}

% --- Caption styling ---
\usepackage{caption}
\captionsetup{font=small, labelfont=bf}

\title{Final Project Proposal}
\author{
\begin{tabular}{c c c}
YuChen (Jean) Lin & Pakhi Chatterjee & Aditya Pandey\\
\texttt{lin.4842@osu.edu} & \texttt{chatterjee.197@osu.edu} & \texttt{pandey.172@osu.edu}
\end{tabular}
}
\date{}

\begin{document}

\maketitle

\section{Problem Statement}
Toxic comment detection models for Japanese are typically trained and evaluated on native-script text (kanji/kana). In practice, however, social text often appears in rōmaji (romanized Japanese) for ease of typing, stylistic effect, or to evade filters. Yet most open models are not evaluated for \textit{script invariance}: whether predictions stay stable when only the script changes and the underlying Japanese sentence stays the same. \\
\\
If a model flags \begin{CJK}{UTF8}{min}最低だ\end{CJK} as toxic but misses the semantically identical "saiteida," moderation quality and fairness suffer. Recent Japanese toxicity resources exist, but they focus on native script; a paired, cross-script robustness evaluation is missing. We target that gap by building a lightweight script-invariant toxicity pipeline and a paired testbed that measures label stability when only the script changes. 

\section{Motivation}
Japan has tightened penalties for online insults in 2022, making serious cases punishable by up to one year of imprisonment, so reliable toxicity detection in Japanese is no longer just an academic concern. At the same time, moderation quality is known to be uneven outside English, with evidence of under-investment and patchy language coverage across platforms. Romanized Japanese is ubiquitous because standard IMEs accept rōmaji keystrokes and convert them to kana/kanji; users can also intentionally leave text unconverted. \\
\\
If safety systems only work reliably on native script, they will systematically miss toxic content written in rōmaji and treat some speakers less fairly than others. We therefore treat romanized Japanese as a \textit{first-class input type} and ask whether modern models actually behave robustly under script changes.  

\section{Research Gap}
Recent Japanese toxicity datasets such as LLM-jp's Japanese Toxicity Dataset (v2)\cite{llmjp2024toxicity} provide manually labeled toxic comments in native Japanese to support safer LLMs. Industry work on Japanese toxicity detection emphasizes efficiency and deployment concerns but similarly evaluates almost exclusively on native script. Parallel native/romanized benchmarks for Japanese toxicity are, to our knowledge, missing. \\
\\
Romanized text has been recognized as a real failure mode in other languages. For example, Roman Urdu hate-speech detection work constructs dedicated datasets and models because romanization changes surface forms and challenges tokenizers \cite{mathur2020hateval}. A recent Nature-style line of work on multilingual toxicity \cite{nature2024multilingual} highlights script-agnostic robustness as a key requirement for safe moderation, but no equivalent study has focused on Japanese rōmaji. \\
\\
Separately, modern NLP offers heterogeneous modeling approaches:
\begin{itemize}
\item \textbf{Language-specific subword models} such as Japanese BERT \cite{bertjapanesemodel} are strong native-script baselines widely fine-tuned for Japanese tasks.
\item \textbf{Multilingual subword models} such as mDeBERTa-v3 \cite{mdebertav3model} are pre-trained on the CC100 corpus covering ~100 languages, including Japanese, offering a cross-lingual baseline.
\item \textbf{Tokenizer-free models} such as ByT5 \cite{googlebyt5model} operate directly on raw UTF-8 bytes rather than on subword tokens, and are advertised as more robust to spelling noise and script issues.
\end{itemize}
However, we lack a systematic comparison of these model families on a script-controlled Japanese toxicity benchmark. This project fills that gap by building a paired native/romaji Japanese toxicity dataset and comparing how a language-specific subword model, a multilingual subword model, and a tokenizer-free byte-level model behave under script changes.

\section{Technical Resources and Datasets}
\subsection{Models}
\begin{itemize}
\item BERT base Japanese (Hugging Face) \cite{bertjapanesemodel}
\item Microsoft DeBERTaV3 (Hugging Face) \cite{mdebertav3model}
\item ByT5 - Small (Hugging Face) \cite{googlebyt5model}
\end{itemize}

\subsection{Training Datasets}
\begin{itemize}
\item llm-jp-toxicity-dataset \cite{llmjp2024toxicity}: Japanese toxicity dataset with LLM‐provided quality assessments and statistics 
\item inspection-ai/japanese-toxic-dataset \cite{inspection2024japanese}: Contains native Japanese text with toxicity level annotations
\end{itemize} 

\subsection{Romanization Pipeline}
pykakasi (v2.2+) \cite{pykakasi2024} for reliable Japanese-to-romaji conversion using Hepburn romanization standard 

\subsection{Compute Resources}
\begin{itemize}
\item Single GPU instance (e.g., NVIDIA V100, 16 GB) 
\item Python 3.9, PyTorch, Hugging Face Transformers
\end{itemize}

\section{Proposed Approach}
\subsection{Data Preprocessing and Validation}
\begin{itemize}
\item Convert Japanese datasets to romaji using pykakasi with Hepburn romanization 
\item Manually inspect 200 random samples; record and fix conversion errors (e.g., loanwords, long vowels)
\item Create train/validation/test splits (70/15/15) maintaining toxicity level distribution 
\item Produce summary statistics: token counts, class distributions
\end{itemize}

\subsection{Model Fine-tuning}
\begin{itemize}
\item Fine-tune three model architectures on binary toxicity classification:
  \begin{itemize}
  \item \textbf{BERT base Japanese} (tohoku-nlp/bert-base-japanese-v3): Language-specific subword model with MeCab tokenizer
  \item \textbf{mDeBERTa-v3 base} (microsoft/mdeberta-v3-base): Multilingual subword model pre-trained on 100+ languages
  \item \textbf{ByT5-small} (google/byt5-small): Tokenization-free byte-level encoder-decoder model
  \end{itemize}
\item Train each model on both native Japanese and romanized (rōmaji) text independently to measure script-invariance
\item Implement stratified train/test split (80/20) to maintain toxicity class distribution and ensure reproducibility via fixed random seed
\item Use standard hyperparameters: learning rate 2e-5, batch size 16, 3 epochs, AdamW optimizer, dropout 0.1
\item Save best model checkpoint based on validation accuracy for each configuration (model × script type)
\end{itemize} 

\section{Evaluation}
\subsection{Classification Performance}
\begin{itemize}
\item F1\_native: Precision, Recall, and F1-score on the held-out native-script test set (per level and macro-averaged)
\item F1\_romaji: Precision, Recall, and F1-score on the held-out romaji test set (per level and macro-averaged)
\end{itemize}

\subsection{Script-Invariance Gap}
\begin{itemize}
\item For each toxicity level:
\[
\Delta F_1 = F_{1,\text{native}} - F_{1,\text{r\={o}maji}}
\]
report mean $\Delta$F1 and 95\% confidence interval
\item Label Consistency Rate: \% of test instances whose predicted label is identical in native and romaji forms (Flip rate = 1 - Consistency).
\end{itemize}

\subsection{Statistical Significance}
\begin{itemize}
\item McNemar's Test: Conduct McNemar's test on paired native versus romaji predictions to determine if the difference in error rates is statistically significant
\end{itemize}

\subsection{Robustness to Romanization Variants}
\begin{itemize}
\item For each common perturbation (long-vowel representation, gemination, numeric leet), compute 
\[
\Delta F_{1,\text{variant}} = F_{1,\text{r\={o}maji}} - F_{1,\text{variant}}
\]
report mean and standard deviation
\end{itemize}

\subsection{Error Analysis on Romanized Inputs}
\begin{itemize}
\item High-$\Delta$F1 Case Review: Manually examine the top 50 samples with the largest native–romaji F1 discrepancy to identify systematic romanization failure modes
\end{itemize}

\subsection{Efficiency Metrics for Deployment (Optional)}
\begin{itemize}
\item Inference latency (ms/sample) and throughput (samples/s) on GPU and CPU
\item Peak GPU memory usage during batch inference
\end{itemize} 

\section{Expected Outcomes}
\begin{itemize}
\item A paired, script-controlled benchmark for Japanese toxicity detection
\item A drop-in training recipe (romanization + consistency loss) that reduces flip rate without sacrificing F1
\item Reproducible code and dataset construction scripts for future Japanese moderation research (and portability to other languages with romanization)
\end{itemize} 

\begin{thebibliography}{9}

\bibitem{mathur2020hateval}
Hammad Rizwan, Muhammad Haroon Shakeel, and Asim Karim. 2020. Hate-Speech and Offensive Language Detection in Roman Urdu.
\textit{In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)}, pages 2512–2522, Online. Association for Computational Linguistics.
\url{https://doi.org/10.18653/v1/2020.emnlp-main.197}

\bibitem{nature2024multilingual}
Ashiq, W., Kanwal, S., Rafique, A. et al. Roman urdu hate speech detection using hybrid machine learning models and hyperparameter optimization. Sci Rep 14, 28590 (2024).
\url{https://doi.org/10.1038/s41598-024-79106-7}

\bibitem{bertjapanesemodel}
Tohoku NLP. (n.d.). \textit{bert-base-japanese-v3}. Hugging Face.\\
\url{https://huggingface.co/tohoku-nlp/bert-base-japanese-v3}

\bibitem{mdebertav3model}
Microsoft. (n.d.). \textit{mdeberta-v3-base}. Hugging Face.\\
\url{https://huggingface.co/microsoft/mdeberta-v3-base}

\bibitem{googlebyt5model}
Google. (n.d.). \textit {byt5-small}. Hugging Face.\\
\url{https://huggingface.co/google/byt5-small}

\bibitem{llmjp2024toxicity}
LLM-jp Consortium (2024).
\textit{Japanese Toxicity Dataset v2}.
\url{https://gitlab.llm-jp.nii.ac.jp/datasets/llm-jp-toxicity-dataset-v2}

\bibitem{inspection2024japanese}
Inspection AI (2024).
\textit{Japanese Toxic Dataset}.
\url{https://github.com/inspection-ai/japanese-toxic-dataset}

\bibitem{pykakasi2024}
pykakasi Development Team (2024).
\textit{pykakasi: Japanese text transliteration library}.
\url{https://pypi.org/project/pykakasi}

\bibitem{emnlp2022industry}
Oikawa, Yuto, Yuki Nakayama, and Koji Murakami. 2022. 
\textit{A Stacking-based Efficient Method for Toxic Language Detection on Live Streaming Chat.} 
In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing: Industry Track, pages 571–578, Abu Dhabi, United Arab Emirates. Association for Computational Linguistics.
\url{https://doi.org/10.18653/v1/2022.emnlp-industry.58}

\end{thebibliography} 

\end{document}